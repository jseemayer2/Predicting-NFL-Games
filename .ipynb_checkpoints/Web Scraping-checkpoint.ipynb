{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect game links to pages where we can scrape our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends = []\n",
    "#1966 season\n",
    "weeks = range(1,19)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1966/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends.append(game_link_ends0.strip())\n",
    "#1967 season\n",
    "weeks = range(1,21)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1967/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends.append(game_link_ends0.strip())\n",
    "#1968 season\n",
    "weeks = range(1,19)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1968/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends.append(game_link_ends0.strip())\n",
    "#14 game seasons (1969-1977)\n",
    "years = range(1969,1978)\n",
    "weeks = range(1,18)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends.append(game_link_ends0.strip())\n",
    "#16 game seasons pre-1982 player strike (1978-1981)\n",
    "years = range(1978,1982)\n",
    "weeks = range(1,21)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends.append(game_link_ends0.strip())\n",
    "#1982 season (shortened by player strike)\n",
    "weeks = [1,2,11,12,13,14,15,16,17,18,19,20]\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1982/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends.append(game_link_ends0.strip())\n",
    "#16 game seasons post-1982 player strike (1983-1989)\n",
    "years = range(1983,1990)\n",
    "weeks = range(1,21)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends.append(game_link_ends0.strip())\n",
    "#Modern schedule format (16 game + bye week)\n",
    "years = range(1990, 2021)\n",
    "weeks = range(1,22)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12788"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_link_ends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get to the actual game pages where we can extract data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.pro-football-reference.com'\n",
    "url_list = []\n",
    "for game_link in game_link_ends:\n",
    "    url = ''.join([url2, game_link])\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12788 12788\n"
     ]
    }
   ],
   "source": [
    "#Sanity checks to make sure we get all the boxscore links & subsequent pages (12989 in elo_csv)\n",
    "#print(*url_list, sep='\\n')\n",
    "print(len(url_list), len(game_link_ends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_stat_dict(url):\n",
    "    '''\n",
    "    From Pro-Football-Reference link stub, request gamepage, parse with BeautifulSoup, and\n",
    "    collect \n",
    "        - game info (possible target application)\n",
    "        - traditional stats (features)\n",
    "        - efficiency stats (features)\n",
    "    Return total & stats as a dictionary.\n",
    "    ''' \n",
    "    game_dict={}\n",
    "    \n",
    "    game_dict['game_id'] = url[49:57] + url[58:61]\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    page = page.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    #scrape teams & team stats box for traditional metrics\n",
    "    data1 = []\n",
    "    #table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "    table1 = soup.find(id=\"div_team_stats\")\n",
    "    table_body1 = table1.find('tbody')\n",
    "\n",
    "    headers1 = table1.find('thead')\n",
    "    head1 = headers1.find_all('th')\n",
    "    teams = [head.text for head in head1 if len(head) > 0]\n",
    "    game_dict['team1'] = teams[1]\n",
    "    game_dict['team2'] = teams[0]\n",
    "\n",
    "    rows1 = table_body1.find_all('tr')\n",
    "    for row in rows1:\n",
    "        cols = row.find_all('td')\n",
    "        #cols = [ele.text.strip() for ele in cols]\n",
    "        data1.append([ele.text for ele in cols if ele]) # Get rid of empty values\n",
    "    \n",
    "    game_dict['1st_downs_team1'] = data1[0][1]\n",
    "    #separate rush stats & make appropriate transformations\n",
    "    rush_stats = [item.split('-') for item in data1[1]]\n",
    "    game_dict['rush_att_team1'] = int(rush_stats[1][0])\n",
    "    game_dict['rush_yds_team1'] = int(rush_stats[1][1])\n",
    "    game_dict['rush_tds_team1'] = int(rush_stats[1][2])\n",
    "    game_dict['rush_att_team2'] = int(rush_stats[0][0])\n",
    "    game_dict['rush_yds_team2'] = int(rush_stats[0][1])\n",
    "    game_dict['rush_tds_team2'] = int(rush_stats[0][2])\n",
    "    #separate pass stats & make appropriate transformations\n",
    "    pass_stats = [item.split('-') for item in data1[2]]\n",
    "    game_dict['comp_team1'] = int(pass_stats[1][0])\n",
    "    game_dict['pass_att_team1'] = int(pass_stats[1][1])\n",
    "    game_dict['pass_yds_team1'] = int(pass_stats[1][2])\n",
    "    game_dict['pass_tds_team1'] = int(pass_stats[1][3])\n",
    "    game_dict['int_team1'] = int(pass_stats[1][4])\n",
    "    game_dict['comp_team2'] = int(pass_stats[0][0])\n",
    "    game_dict['pass_att_team2'] = int(pass_stats[0][1])\n",
    "    game_dict['pass_yds_team2'] = int(pass_stats[0][2])\n",
    "    game_dict['pass_tds_team2'] = int(pass_stats[0][3])\n",
    "    game_dict['pass_tds_team2'] = int(pass_stats[0][4])\n",
    "    #separate sack stats & make appropriate transformations\n",
    "    sack_stats = [item.split('-') for item in data1[3]]\n",
    "    game_dict['sacked_team1'] = int(sack_stats[1][0])\n",
    "    game_dict['sacked_yds_team1'] = int(sack_stats[1][1])\n",
    "    game_dict['sacked_team2'] = int(sack_stats[0][0])\n",
    "    game_dict['sacked_yds_team2'] = int(sack_stats[0][1])\n",
    "    #net pass yards & total yards (stats don't require splits)\n",
    "    game_dict['net_pass_yds_team1'] = int(data1[4][1])\n",
    "    game_dict['total_yds_team1'] = int(data1[5][1])\n",
    "    game_dict['net_pass_yds_team2'] = int(data1[4][0])\n",
    "    game_dict['total_yds_team2'] = int(data1[5][0]) \n",
    "    #separate fumbles & make appropriate transformations\n",
    "    fum_stats = [item.split('-') for item in data1[6]]\n",
    "    game_dict['fumbles_team1'] = int(fum_stats[1][0])\n",
    "    game_dict['fumbles_lost_team1'] = int(fum_stats[1][1])\n",
    "    game_dict['fumbles_team2'] = int(fum_stats[0][0])\n",
    "    game_dict['fumbles_lost_team2'] = int(fum_stats[0][1])\n",
    "    #turnover stats (doesn't require split)\n",
    "    game_dict['turnovers_team1'] = int(data1[7][1])\n",
    "    game_dict['turnovers_team2'] = int(data1[7][0])\n",
    "    #separate penalty stats & make appropriate transformations\n",
    "    pen_stats = [item.split('-') for item in data1[8]]\n",
    "    game_dict['penalties_team1'] = int(pen_stats[1][0])\n",
    "    game_dict['pen_yds_team1'] = int(pen_stats[1][1])\n",
    "    game_dict['penalties_team2'] = int(pen_stats[0][0])\n",
    "    game_dict['pen_yds_team2'] = int(pen_stats[0][1])\n",
    "    \n",
    "    #scrape offesnive player stats box\n",
    "    data2 = []\n",
    "    data3 = []\n",
    "    #table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "    table1 = soup.find(id=\"div_player_offense\")\n",
    "    table_body1 = table1.find('tbody')\n",
    "\n",
    "    rows1 = table_body1.find_all('tr')\n",
    "    for row in rows1:\n",
    "        players = row.find_all('th')\n",
    "        cols = row.find_all('td')\n",
    "        #cols = [ele.text.strip() for ele in cols]\n",
    "        data2.append([ele.text.strip() for ele in players if ele])\n",
    "        for ele in data2:\n",
    "            if len(ele) > 1:\n",
    "                data2.remove(ele)\n",
    "        data3.append([ele.text for ele in cols])\n",
    "    #do twice to remove empty header rows\n",
    "    for ele in data3:\n",
    "        if len(ele) == 0:\n",
    "            data3.remove(ele)\n",
    "    for ele in data3:\n",
    "        if len(ele) == 0:\n",
    "            data3.remove(ele)\n",
    "    data21 = tuple(item for sublist in data2 for item in sublist)\n",
    "    data31 = tuple(data3)\n",
    "    off_player_dict = dict(zip(data21,data31))\n",
    "    game_dict['off_player_dict'] = off_player_dict\n",
    "    \n",
    "    year = int(url[49:53])\n",
    "    if year >= 1978:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting box scores for the different season lengths and schedule formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends1 = []\n",
    "#1966 season\n",
    "weeks = range(1,19)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1966/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends1.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends2 = []\n",
    "#1967 season\n",
    "weeks = range(1,21)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1967/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends2.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends3 = []\n",
    "#1968 season\n",
    "weeks = range(1,19)\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1968/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends3.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends4 = []\n",
    "#14 game seasons (1969-1977)\n",
    "years = range(1969,1978)\n",
    "weeks = range(1,18)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends4.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends5 = []\n",
    "#16 game seasons pre- 1982 player strike (1978-1981)\n",
    "years = range(1978,1982)\n",
    "weeks = range(1,21)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends5.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends6 = []\n",
    "#1982 season (shortened by player strike)\n",
    "weeks = [1,2,11,12,13,14,15,16,17,18,19,20]\n",
    "for week in weeks:\n",
    "    url0 = 'https://www.pro-football-reference.com/years/1982/week_{}.htm'.format(week)\n",
    "    response0 = requests.get(url0)\n",
    "    page0 = response0.text\n",
    "    page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "    soup0 = BeautifulSoup(page0)\n",
    "    for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "        url1 = link.findNext()\n",
    "        game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                            #calling index by attr (url['href']) act the same!\n",
    "        game_link_ends6.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_link_ends7 = []\n",
    "#16 game seasons post-1982 player strike (1983-1989)\n",
    "years = range(1983,1990)\n",
    "weeks = range(1,21)\n",
    "for year in years:\n",
    "    for week in weeks:\n",
    "        url0 = 'https://www.pro-football-reference.com/years/{}/week_{}.htm'.format(year, week)\n",
    "        response0 = requests.get(url0)\n",
    "        page0 = response0.text\n",
    "        page0 = page0.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "        soup0 = BeautifulSoup(page0)\n",
    "        for link in soup0.find_all(class_=\"right gamelink\"):\n",
    "            url1 = link.findNext()\n",
    "            game_link_ends0 = url1.get('href')  #.get() method and \n",
    "                                                #calling index by attr (url['href']) act the same!\n",
    "            game_link_ends7.append(game_link_ends0.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_link_ends7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.pro-football-reference.com/boxscores/196609100gnb.htm'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = url_list[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be on the right page. Know the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dict={}\n",
    "    \n",
    "game_dict['game_id'] = url[49:57] + url[58:61]\n",
    "\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "page = page.replace(\"<!--\",\"\").replace(\"-->\",\"\")\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': '19660910gnb'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stats from appropriate tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape teams & team stats box for traditional metrics\n",
    "data1 = []\n",
    "#table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "table1 = soup.find(id=\"div_team_stats\")\n",
    "table_body1 = table1.find('tbody')\n",
    "\n",
    "headers1 = table1.find('thead')\n",
    "head1 = headers1.find_all('th')\n",
    "teams = [head.text for head in head1 if len(head) > 0]\n",
    "game_dict['team1'] = teams[1]\n",
    "game_dict['team2'] = teams[0]\n",
    "\n",
    "rows1 = table_body1.find_all('tr')\n",
    "for row in rows1:\n",
    "    cols = row.find_all('td')\n",
    "    #cols = [ele.text.strip() for ele in cols]\n",
    "    data1.append([ele.text for ele in cols if ele]) # Get rid of empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': '19660910gnb',\n",
       " 'team1': 'GNB',\n",
       " 'team2': 'BAL',\n",
       " '1st_downs_team1': '17',\n",
       " 'rush_att_team1': 35,\n",
       " 'rush_yds_team1': 155,\n",
       " 'rush_tds_team1': 1,\n",
       " 'rush_att_team2': 32,\n",
       " 'rush_yds_team2': 112,\n",
       " 'rush_tds_team2': 0,\n",
       " 'comp_team1': 14,\n",
       " 'pass_att_team1': 19,\n",
       " 'pass_yds_team1': 138,\n",
       " 'pass_tds_team1': 0,\n",
       " 'int_team1': 1,\n",
       " 'comp_team2': 14,\n",
       " 'pass_att_team2': 21,\n",
       " 'pass_yds_team2': 106,\n",
       " 'pass_tds_team2': 3,\n",
       " 'sacked_team1': 1,\n",
       " 'sacked_yds_team1': 1,\n",
       " 'sacked_team2': 1,\n",
       " 'sacked_yds_team2': 5,\n",
       " 'net_pass_yds_team1': 137,\n",
       " 'total_yds_team1': 292,\n",
       " 'net_pass_yds_team2': 101,\n",
       " 'total_yds_team2': 213,\n",
       " 'fumbles_team1': 0,\n",
       " 'fumbles_lost_team1': 0,\n",
       " 'fumbles_team2': 0,\n",
       " 'fumbles_lost_team2': 0,\n",
       " 'turnovers_team1': 1,\n",
       " 'turnovers_team2': 3,\n",
       " 'penalties_team1': 1,\n",
       " 'pen_yds_team1': 5,\n",
       " 'penalties_team2': 0,\n",
       " 'pen_yds_team2': 0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dict['1st_downs_team1'] = data1[0][1]\n",
    "#separate rush stats & make appropriate transformations\n",
    "rush_stats = [item.split('-') for item in data1[1]]\n",
    "game_dict['rush_att_team1'] = int(rush_stats[1][0])\n",
    "game_dict['rush_yds_team1'] = int(rush_stats[1][1])\n",
    "game_dict['rush_tds_team1'] = int(rush_stats[1][2])\n",
    "game_dict['rush_att_team2'] = int(rush_stats[0][0])\n",
    "game_dict['rush_yds_team2'] = int(rush_stats[0][1])\n",
    "game_dict['rush_tds_team2'] = int(rush_stats[0][2])\n",
    "#separate pass stats & make appropriate transformations\n",
    "pass_stats = [item.split('-') for item in data1[2]]\n",
    "game_dict['comp_team1'] = int(pass_stats[1][0])\n",
    "game_dict['pass_att_team1'] = int(pass_stats[1][1])\n",
    "game_dict['pass_yds_team1'] = int(pass_stats[1][2])\n",
    "game_dict['pass_tds_team1'] = int(pass_stats[1][3])\n",
    "game_dict['int_team1'] = int(pass_stats[1][4])\n",
    "game_dict['comp_team2'] = int(pass_stats[0][0])\n",
    "game_dict['pass_att_team2'] = int(pass_stats[0][1])\n",
    "game_dict['pass_yds_team2'] = int(pass_stats[0][2])\n",
    "game_dict['pass_tds_team2'] = int(pass_stats[0][3])\n",
    "game_dict['pass_tds_team2'] = int(pass_stats[0][4])\n",
    "#separate sack stats & make appropriate transformations\n",
    "sack_stats = [item.split('-') for item in data1[3]]\n",
    "game_dict['sacked_team1'] = int(sack_stats[1][0])\n",
    "game_dict['sacked_yds_team1'] = int(sack_stats[1][1])\n",
    "game_dict['sacked_team2'] = int(sack_stats[0][0])\n",
    "game_dict['sacked_yds_team2'] = int(sack_stats[0][1])\n",
    "#net pass yards & total yards (stats don't require splits)\n",
    "game_dict['net_pass_yds_team1'] = int(data1[4][1])\n",
    "game_dict['total_yds_team1'] = int(data1[5][1])\n",
    "game_dict['net_pass_yds_team2'] = int(data1[4][0])\n",
    "game_dict['total_yds_team2'] = int(data1[5][0]) \n",
    "#separate fumbles & make appropriate transformations\n",
    "fum_stats = [item.split('-') for item in data1[6]]\n",
    "game_dict['fumbles_team1'] = int(fum_stats[1][0])\n",
    "game_dict['fumbles_lost_team1'] = int(fum_stats[1][1])\n",
    "game_dict['fumbles_team2'] = int(fum_stats[0][0])\n",
    "game_dict['fumbles_lost_team2'] = int(fum_stats[0][1])\n",
    "#turnover stats (doesn't require split)\n",
    "game_dict['turnovers_team1'] = int(data1[7][1])\n",
    "game_dict['turnovers_team2'] = int(data1[7][0])\n",
    "#separate penalty stats & make appropriate transformations\n",
    "pen_stats = [item.split('-') for item in data1[8]]\n",
    "game_dict['penalties_team1'] = int(pen_stats[1][0])\n",
    "game_dict['pen_yds_team1'] = int(pen_stats[1][1])\n",
    "game_dict['penalties_team2'] = int(pen_stats[0][0])\n",
    "game_dict['pen_yds_team2'] = int(pen_stats[0][1])\n",
    "\n",
    "game_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape offesnive player stats box\n",
    "data2 = []\n",
    "data3 = []\n",
    "#table1 = soup.find('table', class_=\"add_controls stats_table\")\n",
    "table1 = soup.find(id=\"div_player_offense\")\n",
    "table_body1 = table1.find('tbody')\n",
    "\n",
    "rows1 = table_body1.find_all('tr')\n",
    "for row in rows1:\n",
    "    players = row.find_all('th')\n",
    "    cols = row.find_all('td')\n",
    "    #cols = [ele.text.strip() for ele in cols]\n",
    "    data2.append([ele.text.strip() for ele in players if ele])\n",
    "    for ele in data2:\n",
    "        if len(ele) > 1:\n",
    "            data2.remove(ele)\n",
    "    data3.append([ele.text for ele in cols])\n",
    "#do twice to remove empty header rows\n",
    "for ele in data3:\n",
    "    if len(ele) == 0:\n",
    "        data3.remove(ele)\n",
    "for ele in data3:\n",
    "    if len(ele) == 0:\n",
    "        data3.remove(ele)\n",
    "data21 = tuple(item for sublist in data2 for item in sublist)\n",
    "data31 = tuple(data3)\n",
    "off_player_dict = dict(zip(data21,data31))\n",
    "game_dict['off_player_dict'] = off_player_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_id': '19660910gnb',\n",
       " 'team1': 'GNB',\n",
       " 'team2': 'BAL',\n",
       " '1st_downs_team1': '17',\n",
       " 'rush_att_team1': 35,\n",
       " 'rush_yds_team1': 155,\n",
       " 'rush_tds_team1': 1,\n",
       " 'rush_att_team2': 32,\n",
       " 'rush_yds_team2': 112,\n",
       " 'rush_tds_team2': 0,\n",
       " 'comp_team1': 14,\n",
       " 'pass_att_team1': 19,\n",
       " 'pass_yds_team1': 138,\n",
       " 'pass_tds_team1': 0,\n",
       " 'int_team1': 1,\n",
       " 'comp_team2': 14,\n",
       " 'pass_att_team2': 21,\n",
       " 'pass_yds_team2': 106,\n",
       " 'pass_tds_team2': 3,\n",
       " 'sacked_team1': 1,\n",
       " 'sacked_yds_team1': 1,\n",
       " 'sacked_team2': 1,\n",
       " 'sacked_yds_team2': 5,\n",
       " 'net_pass_yds_team1': 137,\n",
       " 'total_yds_team1': 292,\n",
       " 'net_pass_yds_team2': 101,\n",
       " 'total_yds_team2': 213,\n",
       " 'fumbles_team1': 0,\n",
       " 'fumbles_lost_team1': 0,\n",
       " 'fumbles_team2': 0,\n",
       " 'fumbles_lost_team2': 0,\n",
       " 'turnovers_team1': 1,\n",
       " 'turnovers_team2': 3,\n",
       " 'penalties_team1': 1,\n",
       " 'pen_yds_team1': 5,\n",
       " 'penalties_team2': 0,\n",
       " 'pen_yds_team2': 0,\n",
       " 'off_player_dict': {'Johnny Unitas': ['BAL',\n",
       "   '14',\n",
       "   '20',\n",
       "   '106',\n",
       "   '0',\n",
       "   '3',\n",
       "   '',\n",
       "   '',\n",
       "   '18',\n",
       "   '42.9',\n",
       "   '3',\n",
       "   '12',\n",
       "   '0',\n",
       "   '8',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Gary Cuozzo': ['BAL',\n",
       "   '0',\n",
       "   '1',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '39.6',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Jerry Hill': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '13',\n",
       "   '51',\n",
       "   '0',\n",
       "   '8',\n",
       "   '2',\n",
       "   '10',\n",
       "   '0',\n",
       "   '7'],\n",
       "  'Tony Lorick': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '7',\n",
       "   '25',\n",
       "   '0',\n",
       "   '9',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Lenny Moore': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '8',\n",
       "   '21',\n",
       "   '0',\n",
       "   '13',\n",
       "   '2',\n",
       "   '10',\n",
       "   '0',\n",
       "   '12'],\n",
       "  'Tom Matte': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '1',\n",
       "   '3',\n",
       "   '0',\n",
       "   '3',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Raymond Berry': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '5',\n",
       "   '40',\n",
       "   '0',\n",
       "   '10'],\n",
       "  'John Mackey': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '4',\n",
       "   '34',\n",
       "   '0',\n",
       "   '18'],\n",
       "  'Willie Richardson': ['BAL',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '1',\n",
       "   '12',\n",
       "   '0',\n",
       "   '12'],\n",
       "  'Bart Starr': ['GNB',\n",
       "   '14',\n",
       "   '19',\n",
       "   '138',\n",
       "   '0',\n",
       "   '1',\n",
       "   '',\n",
       "   '',\n",
       "   '25',\n",
       "   '71.8',\n",
       "   '3',\n",
       "   '36',\n",
       "   '1',\n",
       "   '21',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Jim Taylor': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '16',\n",
       "   '76',\n",
       "   '0',\n",
       "   '18',\n",
       "   '1',\n",
       "   '21',\n",
       "   '0',\n",
       "   '21'],\n",
       "  'Paul Hornung': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '14',\n",
       "   '34',\n",
       "   '0',\n",
       "   '8',\n",
       "   '3',\n",
       "   '16',\n",
       "   '0',\n",
       "   '12'],\n",
       "  'Donny Anderson': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '1',\n",
       "   '6',\n",
       "   '0',\n",
       "   '6',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Jim Grabowski': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '1',\n",
       "   '3',\n",
       "   '0',\n",
       "   '3',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   ''],\n",
       "  'Boyd Dowler': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '6',\n",
       "   '73',\n",
       "   '0',\n",
       "   '25'],\n",
       "  'Marv Fleming': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '3',\n",
       "   '16',\n",
       "   '0',\n",
       "   '8'],\n",
       "  'Carroll Dale': ['GNB',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '',\n",
       "   '1',\n",
       "   '12',\n",
       "   '0',\n",
       "   '12']}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
